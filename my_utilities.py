"""Custom utility functions for this project"""

import time
import progressbar
import numpy as np
import pandas as pd
from sklearn.base import clone
from pandarallel import pandarallel


def build_full_data(df, unique_items, max_n_first_items=10):
    """Build full data of samples with one of more first items

    Parameters
    ----------
    df: pandas DataFrame
        A data of samples (with no split into first vs other items)
    unique_items: list
        A list of item identifiers
    max_n_first_items: int
        The maximum number of first items considered

    Returns
    -------
    X: array of size (n_samples, n_features)
        A feature matrix
    y: array of size (n_samples, n_items)
        The corresponding target matrix
    """
    df_features, df_target = split_df_features_target(
        df, unique_items, n_first_items=1
    )
    X = make_feature_matrix(df_features, unique_items)
    y = make_target_matrix(df_target, unique_items)
    for n_first_items in range(2, max_n_first_items):
        df_features, df_target = split_df_features_target(
            df, unique_items, n_first_items
        )
        if df_features is None:
            break
        X_tmp = make_feature_matrix(df_features, unique_items)
        y_tmp = make_target_matrix(df_target, unique_items)
        X, y = pd.concat([X, X_tmp]), pd.concat([y, y_tmp])
    return X, y


def split_df_features_target(df, unique_items, n_first_items):
    """Split data frame into features and target

    Parameters
    ----------
    df: pandas DataFrame
        Transaction data
    unique_items: list
        A list of item identifiers
    n_first_items: int
        The number of first items to use to create features

    Returns
    -------
    df_features: pandas DataFrame
        A data frame with features as columns (including the one with
        the list of first items that were purchased)
    df_target: pandas DataFrame
        A data frame with a single target column with the list of items
        that were later purchased
    """
    
    df = df.copy()
    
    # Split the 'items' column to create 'first_items' and
    # 'purchased_items' columns.  Drop rows where it is marked None in
    # the 'first_items' column above.  Stop if no rows are left.
    df['first_items'] = df['items'].apply(
        lambda s:
        s[:n_first_items] if len(s) >= n_first_items
        else None
    )
    df.dropna(inplace=True)
    if len(df) == 0:
        return None, None
    df['purchased_items'] = df['items'].apply(
        lambda s: s[n_first_items:]
    )
    
    # Create and return separate DataFrames for features and targets
    features = [
        'month', 'day_of_month', 'day_of_week', 'hour',
        'first_items'
    ]    
    df_features = df[features]
    df_target = pd.DataFrame(df['purchased_items'])        
    return df_features, df_target


def make_feature_matrix(df_features, unique_items):
    """Creates feature matrix from data

    Paramters
    ---------
    df_features: pandas DataFrame
        A data of features generated by split_df_features_target()
    unique_items: list
        A list of item identifiers

    Returns
    -------
    array of size (n_samples, n_features)
    """

    X = df_features.copy()
    
    # Create a column for the number of occurrence of each item
    for item in unique_items:
        X[item] = X['first_items'].apply(
            lambda items: sum([1 if x == item else 0 for x in items])
        )
    X.drop(labels='first_items', axis=1, inplace=True)
    
    return X


def make_target_matrix(df_target, unique_items):
    """Creates target matrix from data

    Parameters
    ----------
    df_target: pandas DataFrame
        A target data generated by split_df_features_target()
    unique_items: list
        A list of item identifiers

    Returns
    -------
    array of size (n_samples, n_items)
    """
    
    y = df_target.copy()
    
    # Create a column for binary variable of each item
    for item in unique_items:
        y[item] = y['purchased_items'].apply(
            lambda items: 1 if item in items else 0
        )
    y.drop(labels='purchased_items', axis=1, inplace=True)
    
    return y


def train_for_each_column(model, X, y):
    """Trains a clone of the model for each target variable

    Parameters
    ----------
    model: object
        A scikit-learn estimator for which fit method is defined
    X: array
        The feature matrix from the training data
    y: array
        Thge target matrix from the training data

    Returns
    -------
    list
        A list of trained scikit-learn models, one for each column of y
    """

    models = {}
    with progressbar.ProgressBar(max_value=len(y.columns)) as bar:
        for i, item in enumerate(y.columns):
            if y[item].max() > 0:
                models[item] = clone(model)
                models[item].fit(X, y[item])
            else:
                # If only y has only zeros,
                models[item] = None
            bar.update(i)
    return models


def hit_rate(df, scaler, models, n_samples=None, n_resampling=1):
    """Computes hit rate by running a transaction simulation for rows
    of the data

    Parameters
    ----------
    df: DataFrame
        Transaction data
    scaler: 
        scikit-learn scaler (to be used with models)
    models: dict
        A dict of trained scikit-learn models indexed by item
        identifiers.
    n_samples: int
        The number of random sample rows to be used in the calculation.
        Default is to use all rows.

    Returns
    -------
    float
        The hit rate (the probability of a hit)
    """

    if n_samples is None:
        pandarallel.initialize(progress_bar=True)
        is_hit_list = df.parallel_apply(
            lambda row: run_transaction(row, scaler, models),
            axis=1
        )
        return is_hit_list.mean()
    else:
        assert(n_samples <= len(df))
        if n_resampling == 1:
            is_hit_list = df.sample(n_samples).apply(
                lambda row: run_transaction(row, scaler, models),
                axis=1
            )
            return is_hit_list.mean()
        else:
            hit_rates = []
            for i in range(n_resampling):
                is_hit_list = df.sample(n_samples).apply(
                    lambda row: run_transaction(row, scaler, models),
                    axis=1
                )
                hit_rates.append(is_hit_list.mean())
            return hit_rates


def run_transaction(s, scaler, models):
    """Runs a single transaction and determine if there is a "hit"
    
    Parameters
    ----------
    s: pandas Series
        Data for a single transaction
    scaler: 
        scikit-learn scaler (to be used with models)
    models: dict
        A dict of trained scikit-learn models indexed by item
        identifiers.
    
    Returns
    -------
    boolean
        Whether or not there was any "hit" during the transaction
    """

    # All items that can potentially be purchased
    unique_items = list(models.keys())

    # The columns of pandas Series s to be used as features
    features = [
        'month', 'day_of_month', 'day_of_week', 'hour',
        'first_items'
    ]
    
    # All purchases in this transaction
    items = s['items']
    n_items = len(items)
    
    # Run the model for each new item purchase and check for a hit
    unique_recs = []
    is_hit_list = []
    for n_first_items in range(1, n_items + 1):
        
        # Items purchased so far
        s['first_items'] = items[:n_first_items]
        
        # Prepare the feature vector
        X = make_feature_vector(s[features], unique_items)
        X_scaled = scaler.transform(X.values.reshape(1, -1))
        
        # Apply the model and make 3 recommendations
        rec_items = recommend_items(models, X_scaled, num_rec=3)[0]
        
        # Enforce no more than 5 total unique recommendations
        unique_recs = list(set(unique_recs + rec_items))
        if len(unique_recs) > 5: break
        
        # Check for a hit and keep track
        target_list = items[n_first_items:] # Items purchased later
        is_hit = any([item in target_list for item in rec_items])
        is_hit_list.append(is_hit)
        
    # Return boolean: whether or not there was any "hit"
    return any(is_hit_list)


def make_feature_vector(s_features, unique_items):
    """Creates a feature vector for modeling a single transaction
    
    Parameters
    ----------
    s_features: pandas Series 
        A single row from a data frame of features
    unique_items: list
        A list of item identifiers
     
    Returns
    -------
    pandas Series
        A feature that can be fed to a model
    """

    s = s_features.copy()
    
    # Create a variable for the number of occurrence of each item
    for item in unique_items:
        s[item] = sum([x == item for x in s['first_items']])
    s.drop(labels='first_items', inplace=True)
    
    return s


def recommend_items(models, X, num_rec=3):
    """Makes item recommendations from the feature matrix using the
    models
    
    For each sample, it chooses items with the highest predicted
    probabilities.

    Parameters
    ----------
    models: dict
        A dict of trained scikit-learn models indexed by item
        identifiers.
    X: (n_samples, n_features) array
        A feature matrix
    num_rec:
        The number of items to recommend for each sample (default = 3)

    Returns
    -------
    list
        A list of lists of recommended items
    """

    if X.ndim == 1:
        X = X.reshape(1, -1)
    items = list(models.keys())

    # Predict purchase probabilities
    probabilities = np.array([
        models[item].predict_proba(X)[:, 1] if models[item] != None 
        else np.zeros((len(X),))
        for item in items
    ])

    # Make a list of item recommendations from predicted probabilities
    def recommend_items(p, items, num_rec):
        idx = np.argsort(p)[-num_rec:]
        return [items[i] for i in idx]
    rec_items_list = [
        recommend_items(p, items, num_rec) for p in probabilities.T
    ]

    return rec_items_list
